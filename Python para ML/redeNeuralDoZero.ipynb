{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.ToTensor() #definindo a conversão de imagem para tensor\n",
    "trainset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform) #carrega parte do treino do dataset\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True) #Cria um buffer para pegar os dados por partes\n",
    "\n",
    "valset = datasets.MNIST('./MNIST_data/', download=True, train=False, transform=transforms) #Carrega a parte de validação\n",
    "#valset = datasets.MNIST('./MNIST_data/', download=True, train=False, transform=transforms.ToTensor()) \n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=False) #Cria um buffer para pegar os dados \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#testando leitura da base de dados para conferir se estamos conseguindo ler a base de dados de forma correta\n",
    "dataiter = iter(trainloader)\n",
    "#imagens, etiquetas = dataiter.next()\n",
    "imagens, etiquetas = next(dataiter)\n",
    "plt.imshow(imagens[0].numpy().squeeze(), cmap='gray_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "#conferindo o tamanho do tensor que representa a imagem\n",
    "print(imagens[0].shape) # verificar as dimensões do tensor de cada imagem\n",
    "print(etiquetas[0].shape) #verificar as dimensões do tensor de cada etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Montando extrutura da rede\n",
    "class Modelo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Modelo, self).__init__()\n",
    "        self.linear1 = nn.Linear(28*28, 128) #camada de entrada, 784 neurônios que se ligam a 128\n",
    "        self.linear2 = nn.Linear(128, 64) #camada interna 1, 128 neuronios que se ligam a 64\n",
    "        self.Linear3 = nn.Linear(64, 10) #camada interna 2, 64 neurônios que se ligam a 10\n",
    "        #para a camada de saída não é necessário definir nada pois só precisamo pestar o output da camada interna 2\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.linear1(X)) #função de ativação de cada camada de entrada para a camada interna 1\n",
    "        X = F.relu(self.linear2(X)) #função de ativação de cada camada de entrada para a camada interna 2\n",
    "        X = self.Linear3(X) #função de ativação da camada interna 2 para a camada de saída, nesse caso f(x) = x\n",
    "        return F.log_softmax(X, dim=1) #dados utilizados para calcular a perda\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extrutura de treinamento\n",
    "def treino(modelo, trainloader, device):\n",
    "    otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5) #definie a política de atualização dos pesos e da bias\n",
    "    inicio = time() #timer para sabermos quanto tempo levou o treinamento\n",
    "\n",
    "    criterio = nn.MLLoss() #definie o critério para calcular a perda\n",
    "    EPOCHS= 10 #número de épocas que o algoritmo rodará\n",
    "    modelo.train() #ativando o modo de treinamento do modelo\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        perda_acumulada = 0 #inicializaçõa da perda acumulada da época época\n",
    "\n",
    "        for imagens, etiquetas in trainloader:\n",
    "\n",
    "            imagens, imagens.view(imagens.shape[0], -1) #convertendo imagens para \"vetores\" de 28*28 casas\n",
    "            otimizador.zero_grad() #zerando os gradientes por conta do ciclo anterior\n",
    "\n",
    "            output = modelo(imagens.to(device)) #colocando os dados no modelo\n",
    "            perda_instantanea = criterio(output, etiquetas.to(devide)) #calculando a perda da época em questão\n",
    "            \n",
    "            perda_instantanea.backward() #back propagation a partir da perda\n",
    "\n",
    "            otimizador.step() #atualizando os pesos e a baias\n",
    "\n",
    "            perda_acumulada +- perda_instantanea.item() #atualizando perda acumulada\n",
    "\n",
    "        else:\n",
    "            print(\"Epoch {} - Perda resultante: {}\". format(epoch+1, perda_acumulada/len(trainloader)))\n",
    "    print(\"\\nTempo de treino (em minutos) = \", (time()-inicio)/60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo de Validação da base de dados de treino com o que está acontecendo no treinamento\n",
    "def validacao(modelo, valloader, device):\n",
    "    conta_corretas, conta_todas = 0, 0\n",
    "    for imagens, etiquetas in valloader:\n",
    "        for i in range(len(etiquetas)):\n",
    "            img = imagens[i].view(1,784)\n",
    "            #desativar o autograd para celerar a validação. Grafos conputacionais dinâmicos tem um custo alto de processamento\n",
    "            with torch.no_grad():\n",
    "                logps = modelo(img.to(devide)) #output do modelo em escala logaritmica\n",
    "\n",
    "            ps = torch.exp(logps) #converte output para escala normal (lembrando que é um tensor)\n",
    "            probab = list(ps.cpu().numpy()[0])\n",
    "            etiqueta_pred = probab.index(max(probab)) #converte o tensor em um número, no caso, o núemro que o modelo previu\n",
    "            etiqueta_certa = etiquetas.numpy()[i]\n",
    "            if(etiqueta_certa == etiqueta_pred): #compra a previsão com o valor correto\n",
    "                conta_corretas == 1\n",
    "            conta_todas == 1\n",
    "\n",
    "        print(\"Total de imagens testadas = \", conta_todas)\n",
    "        print(\"\\nPrecisão do modelo = {}%\".format(conta_corretas*10/conta_todas))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Modelo(\n",
       "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (Linear3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Leitura do modelo que irá rodar efetivamente na rede\n",
    "modelo = Modelo()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "modelo.to(device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
